{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n"
     ]
    }
   ],
   "source": [
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import random\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "from collections import defaultdict\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import gdal\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from keras import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/kaggle-dstl/keras2-baseline-improvements\n"
     ]
    }
   ],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "N_Cls = 1\n",
    "data_base_dir = \"/home/ubuntu/data/\"\n",
    "inDir = './'\n",
    "mkdir_p(inDir + '/data')\n",
    "out_dir = 'output/'\n",
    "mkdir_p(out_dir)\n",
    "\n",
    "print(os.getcwd())\n",
    "DF = pd.read_csv(data_base_dir+'train_wkt_v4_TREES.csv')\n",
    "val_DF = pd.read_csv(data_base_dir+'val_wkt_v4_TREES.csv')\n",
    "GS = pd.read_csv(data_base_dir+'grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n",
    "SB = pd.read_csv(data_base_dir+'sample_submission.csv')\n",
    "\n",
    "ISZ = 160\n",
    "smooth = 1e-12\n",
    "\n",
    "EPSILON = 2  # polygon edge smoothing factor (higher=less nodes, i.e. less detail)\n",
    "MIN_AREA = 5.  # smallest area a polygon can be\n",
    "\n",
    "val_img_names = [\"6010_4_4\", \"6070_2_3\", \"6100_2_3\", \"6140_1_2\", \"6110_4_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3345, 3393, 3)\n",
      "(837, 848, 8)\n",
      "(3348, 3392, 1)\n"
     ]
    }
   ],
   "source": [
    "def RGB(image_id):\n",
    "    filename = os.path.join(data_base_dir, 'three_band', '{}.tif'.format(image_id))\n",
    "    img = tiff.imread(filename)\n",
    "    img = np.rollaxis(img, 0, 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def P(image_id):\n",
    "    filename = os.path.join(data_base_dir, 'sixteen_band', '{}_P.tif'.format(image_id))\n",
    "    img = tiff.imread(filename)\n",
    "    img = img.reshape(img.shape[0], img.shape[1], 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "#delete me:\n",
    "def M(image_id):\n",
    "    # __author__ = amaia\n",
    "    # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n",
    "    filename = os.path.join(data_base_dir, 'sixteen_band', '{}_M.tif'.format(image_id))\n",
    "    img = tiff.imread(filename)\n",
    "    img = np.rollaxis(img, 0, 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "r=RGB(val_img_names[0])\n",
    "print(r.shape)\n",
    "m=M(val_img_names[0])\n",
    "print(m.shape)\n",
    "\n",
    "p=P(val_img_names[0])\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - np.rollaxis still working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _convert_coordinates_to_raster(coords, img_size, xymax):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    Xmax, Ymax = xymax\n",
    "    H, W = img_size\n",
    "    W1 = 1.0 * W * W / (W + 1)\n",
    "    H1 = 1.0 * H * H / (H + 1)\n",
    "    xf = W1 / Xmax\n",
    "    yf = H1 / Ymax\n",
    "    coords[:, 1] *= yf\n",
    "    coords[:, 0] *= xf\n",
    "    coords_int = np.round(coords).astype(np.int32)\n",
    "    return coords_int\n",
    "\n",
    "\n",
    "def _get_xmax_ymin(grid_sizes_panda, imageId):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n",
    "    return (xmax, ymin)\n",
    "\n",
    "\n",
    "def _get_polygon_list(wkt_list_pandas, imageId, cType):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n",
    "    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n",
    "    polygonList = None\n",
    "    if len(multipoly_def) > 0:\n",
    "        assert len(multipoly_def) == 1\n",
    "        polygonList = wkt_loads(multipoly_def.values[0])\n",
    "    return polygonList\n",
    "\n",
    "\n",
    "def _get_and_convert_contours(polygonList, raster_img_size, xymax):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    perim_list = []\n",
    "    interior_list = []\n",
    "    if polygonList is None:\n",
    "        return None\n",
    "    for k in range(len(polygonList)):\n",
    "        poly = polygonList[k]\n",
    "        perim = np.array(list(poly.exterior.coords))\n",
    "        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n",
    "        perim_list.append(perim_c)\n",
    "        for pi in poly.interiors:\n",
    "            interior = np.array(list(pi.coords))\n",
    "            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n",
    "            interior_list.append(interior_c)\n",
    "    return perim_list, interior_list\n",
    "\n",
    "\n",
    "def _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    img_mask = np.zeros(raster_img_size, np.uint8)\n",
    "    if contours is None:\n",
    "        return img_mask\n",
    "    perim_list, interior_list = contours\n",
    "    cv2.fillPoly(img_mask, perim_list, class_value)\n",
    "    cv2.fillPoly(img_mask, interior_list, 0)\n",
    "    return img_mask\n",
    "\n",
    "\n",
    "def generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)  # for scaling according to competition\n",
    "    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)  # read (training) polygon data\n",
    "    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)  # creating outline from vector nodes\n",
    "    mask = _plot_mask_from_contours(raster_size, contours, 1)  # filling in polygon outlines (i.e. creating the mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# def M(image_id):\n",
    "#     # __author__ = amaia\n",
    "#     # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n",
    "#     filename = os.path.join(data_base_dir, 'sixteen_band', '{}_M.tif'.format(image_id))\n",
    "#     img = tiff.imread(filename)\n",
    "#     img = np.rollaxis(img, 0, 3)\n",
    "#     return img\n",
    "\n",
    "\n",
    "def stretch_n(bands, lower_percent=0, higher_percent=100): # <- \"Claims to improve\" (was lower_percent=5, higher_percent=95)\n",
    "    # \"Contrast enhancement\", see https://www.kaggle.com/aamaia/rgb-using-m-bands-example\n",
    "    out = np.zeros_like(bands).astype(np.float32)\n",
    "    n = bands.shape[2]\n",
    "    for i in range(n):\n",
    "        a = 0  # np.min(band)\n",
    "        b = 1  # np.max(band)\n",
    "        c = np.percentile(bands[:, :, i], lower_percent)\n",
    "        d = np.percentile(bands[:, :, i], higher_percent)\n",
    "        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n",
    "        t[t < a] = a\n",
    "        t[t > b] = b\n",
    "        out[:, :, i] = t\n",
    "\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "    \n",
    "def get_patches(img, msk, amt=10000, aug=True):\n",
    "    is2 = int(1.0 * ISZ)  # ISZ=is2=patch size\n",
    "    xm, ym = img.shape[0] - is2, img.shape[1] - is2  # starting coordinate for getting patches (taking into consideration padding)\n",
    "\n",
    "    x, y = [], []\n",
    "\n",
    "    # threshold determining when to add an image - if the image contains a greater percentage of pixels in the training\n",
    "    # set than specified by the thresholds below:\n",
    "    tr = [0.3]\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for i in range(amt):\n",
    "        do_we_append = False\n",
    "        \n",
    "        # get random point in inner image (i.e exluding the outer image padding)\n",
    "        xc = random.randint(0, xm)\n",
    "        yc = random.randint(0, ym)\n",
    "\n",
    "        # get patch\n",
    "        im = img[xc:xc + is2, yc:yc + is2]\n",
    "        ms = msk[xc:xc + is2, yc:yc + is2]\n",
    "\n",
    "        for j in range(N_Cls):\n",
    "            # sum pixels containing class j\n",
    "            sm = np.sum(ms[:, :, j])\n",
    "            if aug:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    im = im[::-1]\n",
    "                    ms = ms[::-1]\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    im = im[:, ::-1]\n",
    "                    ms = ms[:, ::-1]\n",
    "\n",
    "            # calculate the percent of covered pixels (for one class) - check if greater than threshold.\n",
    "            if 1.0 * sm / is2 ** 2 > tr[j]:\n",
    "                do_we_append = True\n",
    "            \n",
    "            # Add \"blank ones\" with probability 0.1\n",
    "            elif sm < 500:\n",
    "                do_we_append = True\n",
    "                count += 1\n",
    "                print(\"Add blank, idx={}, count={}\".format(i, count))\n",
    "            \n",
    "        if do_we_append:\n",
    "            x.append(im)\n",
    "            y.append(ms)\n",
    "\n",
    "    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))  # Maybe some sort of standardisation/normalisation\n",
    "    print(x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def calc_jacc(model):\n",
    "    img = np.load(inDir + '/data/x_val_%d.npy' % N_Cls)\n",
    "    msk = np.load(inDir + '/data/y_val_%d.npy' % N_Cls)\n",
    "    \n",
    "    print(\"Validation data shapes:\")\n",
    "    print(img.shape)\n",
    "    print(msk.shape)\n",
    "\n",
    "\n",
    "    prd = model.predict(img, batch_size=4)\n",
    "    print(prd.shape, msk.shape)\n",
    "    avg, trs = [], []\n",
    "\n",
    "    for i in range(N_Cls):\n",
    "        t_msk = msk[:, i, :, :]\n",
    "        t_prd = prd[:, i, :, :]\n",
    "        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
    "        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
    "\n",
    "        # grid search the threshold\n",
    "        m, b_tr = 0, 0\n",
    "        for j in range(10):\n",
    "            tr = j / 10.0  # threshold\n",
    "            pred_binary_mask = t_prd > tr\n",
    "\n",
    "            jk = jaccard_similarity_score(t_msk, pred_binary_mask)\n",
    "            if jk > m:\n",
    "                m = jk\n",
    "                b_tr = tr\n",
    "\n",
    "        print(i, m, b_tr)\n",
    "        avg.append(m)\n",
    "        trs.append(b_tr)\n",
    "\n",
    "    score = sum(avg) / 10.0\n",
    "    return prd, score, trs  # trs is the best threshold value (a list, for each of the 10 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_val(aug=False):\n",
    "    print(\"let's pick some samples for validation\")\n",
    "    img = np.load(inDir + '/data/x_valALL_%d.npy' % N_Cls)\n",
    "    msk = np.load(inDir + '/data/y_valALL_%d.npy' % N_Cls)\n",
    "    x, y = get_patches(img, msk, amt=100, aug=aug)  # amt := attempt (maybe - i.e. attempting to create 3000 patches, without\n",
    "                                            # percentage area cover threshold.\n",
    "\n",
    "    print(\"Validation data shapes:\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    np.save(inDir + '/data/x_val_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_val_%d' % N_Cls, y)\n",
    "    \n",
    "    \n",
    "def stick_all_train():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 3300  # size of the RGB images (roughly)\n",
    "\n",
    "    # 25 training images grid\n",
    "    x = np.zeros((5 * s, 4 * s, 3))      # RGB\n",
    "    y = np.zeros((5 * s, 4 * s, N_Cls))  # axis=2 denote the class label\n",
    "\n",
    "    ids = sorted(DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "    \n",
    "    \n",
    "    # x start grid position (based on image size)\n",
    "    for i in range(5):\n",
    "        # y start grid position (based on image size)\n",
    "        for j in range(4):\n",
    "            id = ids[4 * i + j]\n",
    "\n",
    "            img = RGB(id)\n",
    "        \n",
    "            img = stretch_n(img)\n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            \n",
    "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n",
    "            \n",
    "            # generate training masks by class\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n",
    "    \n",
    "    print(\"x shape is:\")\n",
    "    print(x.shape)\n",
    "    print(\"y shape is:\")\n",
    "    print(y.shape)\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "    \n",
    "    np.save(inDir + '/data/x_trn_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_trn_%d' % N_Cls, y)\n",
    "    \n",
    "    \n",
    "def stick_all_val():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 3300  # size of the RG images (roughly)\n",
    "\n",
    "    # 25 training images grid\n",
    "    x = np.zeros((5 * s, 1 * s, 3))      # RGB\n",
    "    y = np.zeros((5 * s, 1 * s, N_Cls))   # axis=2 denote the class label\n",
    "\n",
    "    ids = sorted(val_DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "\n",
    "    # x start grid position (based on image size)\n",
    "    for i in range(5):\n",
    "        # y start grid position (based on image size)\n",
    "        for j in range(1):\n",
    "            id = ids[1 * i + j]\n",
    "\n",
    "            img = RGB(id)\n",
    "            \n",
    "            img = stretch_n(img)\n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            \n",
    "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]  \n",
    "            \n",
    "            # generate training masks by class\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1, wkt_list_pandas=val_DF)[:s, :s]\n",
    "\n",
    "    print(\"x shape is:\")\n",
    "    print(x.shape)\n",
    "    print(\"y shape is:\")\n",
    "    print(y.shape)\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "\n",
    "    np.save(inDir + '/data/x_valALL_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_valALL_%d' % N_Cls, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's stick all imgs together\n",
      "20\n",
      "(3349, 3396, 3) 6010_1_2 1.0 0.0\n",
      "(3345, 3396, 3) 6010_4_2 1.0 0.0\n",
      "(3349, 3391, 3) 6040_1_0 1.0 0.0\n",
      "(3349, 3391, 3) 6040_1_3 1.0 0.0\n",
      "(3349, 3391, 3) 6040_2_2 1.0 0.0\n",
      "(3346, 3387, 3) 6040_4_4 1.0 0.0\n",
      "(3348, 3403, 3) 6060_2_3 1.0 0.0\n",
      "(3349, 3393, 3) 6090_2_0 1.0 0.0\n",
      "(3349, 3391, 3) 6100_1_3 1.0 0.0\n",
      "(3349, 3391, 3) 6100_2_2 1.0 0.0\n",
      "(3348, 3396, 3) 6110_1_2 1.0 0.0\n",
      "(3348, 3396, 3) 6110_3_1 1.0 0.0\n",
      "(3348, 3396, 3) 6110_4_0 1.0 0.0\n",
      "(3348, 3403, 3) 6120_2_0 1.0 0.0\n",
      "(3348, 3403, 3) 6120_2_2 1.0 0.0\n",
      "(3348, 3396, 3) 6140_3_1 1.0 0.0\n",
      "(3348, 3403, 3) 6150_2_3 1.0 0.0\n",
      "(3349, 3393, 3) 6160_2_1 1.0 0.0\n",
      "(3349, 3389, 3) 6170_0_4 1.0 0.0\n",
      "(3345, 3393, 3) 6170_4_1 1.0 0.0\n",
      "x shape is:\n",
      "(16500, 13200, 3)\n",
      "y shape is:\n",
      "(16500, 13200, 1)\n",
      "1.0 0.0\n",
      "let's stick all imgs together\n",
      "5\n",
      "(3345, 3393, 3) 6010_4_4 1.0 0.0\n",
      "(3350, 3338, 3) 6070_2_3 1.0 0.0\n",
      "(3349, 3391, 3) 6100_2_3 1.0 0.0\n",
      "(3348, 3396, 3) 6140_1_2 1.0 0.0\n",
      "(3349, 3389, 3) 6170_2_4 1.0 0.0\n",
      "x shape is:\n",
      "(16500, 3300, 3)\n",
      "y shape is:\n",
      "(16500, 3300, 1)\n",
      "1.0 0.0\n",
      "let's pick some samples for validation\n",
      "Add blank, idx=3, count=1\n",
      "Add blank, idx=4, count=2\n",
      "Add blank, idx=14, count=3\n",
      "Add blank, idx=18, count=4\n",
      "Add blank, idx=19, count=5\n",
      "Add blank, idx=20, count=6\n",
      "Add blank, idx=22, count=7\n",
      "Add blank, idx=23, count=8\n",
      "Add blank, idx=27, count=9\n",
      "Add blank, idx=30, count=10\n",
      "Add blank, idx=35, count=11\n",
      "Add blank, idx=37, count=12\n",
      "Add blank, idx=38, count=13\n",
      "Add blank, idx=43, count=14\n",
      "Add blank, idx=48, count=15\n",
      "Add blank, idx=49, count=16\n",
      "Add blank, idx=52, count=17\n",
      "Add blank, idx=53, count=18\n",
      "Add blank, idx=56, count=19\n",
      "Add blank, idx=59, count=20\n",
      "Add blank, idx=60, count=21\n",
      "Add blank, idx=61, count=22\n",
      "Add blank, idx=62, count=23\n",
      "Add blank, idx=69, count=24\n",
      "Add blank, idx=71, count=25\n",
      "Add blank, idx=73, count=26\n",
      "Add blank, idx=74, count=27\n",
      "Add blank, idx=75, count=28\n",
      "Add blank, idx=76, count=29\n",
      "Add blank, idx=82, count=30\n",
      "Add blank, idx=83, count=31\n",
      "Add blank, idx=88, count=32\n",
      "Add blank, idx=89, count=33\n",
      "Add blank, idx=90, count=34\n",
      "Add blank, idx=91, count=35\n",
      "Add blank, idx=92, count=36\n",
      "Add blank, idx=94, count=37\n",
      "(52, 3, 160, 160) (52, 1, 160, 160) 0.985239863396 -0.99692307692 1.0 0.0\n",
      "Validation data shapes:\n",
      "(52, 3, 160, 160)\n",
      "(52, 1, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "stick_all_train()\n",
    "\n",
    "stick_all_val()\n",
    "make_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet_RGB():\n",
    "    inputs = Input((3, ISZ, ISZ))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(N_Cls, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', \n",
    "                  metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add blank, idx=2, count=1\n",
      "Add blank, idx=12, count=2\n",
      "Add blank, idx=16, count=3\n",
      "Add blank, idx=17, count=4\n",
      "Add blank, idx=19, count=5\n",
      "Add blank, idx=20, count=6\n",
      "Add blank, idx=21, count=7\n",
      "Add blank, idx=26, count=8\n",
      "Add blank, idx=32, count=9\n",
      "Add blank, idx=40, count=10\n",
      "Add blank, idx=42, count=11\n",
      "Add blank, idx=50, count=12\n",
      "Add blank, idx=53, count=13\n",
      "Add blank, idx=55, count=14\n",
      "Add blank, idx=60, count=15\n",
      "Add blank, idx=62, count=16\n",
      "Add blank, idx=65, count=17\n",
      "Add blank, idx=74, count=18\n",
      "Add blank, idx=82, count=19\n",
      "Add blank, idx=88, count=20\n",
      "Add blank, idx=92, count=21\n",
      "Add blank, idx=95, count=22\n",
      "Add blank, idx=111, count=23\n",
      "Add blank, idx=113, count=24\n",
      "Add blank, idx=128, count=25\n",
      "Add blank, idx=134, count=26\n",
      "Add blank, idx=135, count=27\n",
      "Add blank, idx=141, count=28\n",
      "Add blank, idx=143, count=29\n",
      "Add blank, idx=146, count=30\n",
      "Add blank, idx=148, count=31\n",
      "Add blank, idx=149, count=32\n",
      "Add blank, idx=151, count=33\n",
      "Add blank, idx=152, count=34\n",
      "Add blank, idx=157, count=35\n",
      "Add blank, idx=159, count=36\n",
      "Add blank, idx=160, count=37\n",
      "Add blank, idx=169, count=38\n",
      "Add blank, idx=172, count=39\n",
      "Add blank, idx=174, count=40\n",
      "Add blank, idx=179, count=41\n",
      "Add blank, idx=183, count=42\n",
      "Add blank, idx=189, count=43\n",
      "Add blank, idx=192, count=44\n",
      "(54, 3, 160, 160) (54, 1, 160, 160) 0.791208744049 -0.981859410182 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = np.load(inDir + '/data/x_val_%d.npy' % N_Cls), np.load(inDir + '/data/y_val_%d.npy' % N_Cls)\n",
    "img = np.load(inDir + '/data/x_trn_%d.npy' % N_Cls)\n",
    "msk = np.load(inDir + '/data/y_trn_%d.npy' % N_Cls)\n",
    "\n",
    "model = get_unet_RGB()\n",
    "\n",
    "# del x_trn\n",
    "# del y_trn\n",
    "x_trn, y_trn = get_patches(img, msk, amt=200, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 3, 160, 160)\n",
      "(52, 3, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "print(x_trn.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check trn/val images look sensible (to prevent massively different/overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "mkdir_p(\"visualise/trn\")\n",
    "mkdir_p(\"visualise/val\")\n",
    "\n",
    "def save_visual_msk_patch(np_arr, folder, sample_idx=0):\n",
    "    scipy.misc.imsave(\"visualise/{}/{}msk.bmp\".format(folder, sample_idx), np_arr[sample_idx][0])\n",
    "\n",
    "def save_visual_img_patch(np_arr, folder, sample_idx=0, band=0):\n",
    "    scipy.misc.imsave(\"visualise/{}/{}img_{}.bmp\".format(folder, sample_idx, band), np_arr[sample_idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(x_trn.shape[0]):\n",
    "    save_visual_img_patch(x_trn, \"trn\", sample_idx=i)\n",
    "    save_visual_msk_patch(y_trn, \"trn\", sample_idx=i)\n",
    "    \n",
    "for i in range(x_val.shape[0]):\n",
    "    save_visual_img_patch(x_val, \"val\", sample_idx=i)\n",
    "    save_visual_msk_patch(y_val, \"val\", sample_idx=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good - resolution definately better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 52 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 129s - loss: 0.6829 - jaccard_coef: 0.0738 - jaccard_coef_int: 0.0056 - acc: 0.8109 - val_loss: 2.0064 - val_jaccard_coef: 6.0346e-18 - val_jaccard_coef_int: 6.0346e-18 - val_acc: 0.8755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85dbd93da0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 52 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 128s - loss: 1.2886 - jaccard_coef: 9.0485e-18 - jaccard_coef_int: 9.0485e-18 - acc: 0.9201 - val_loss: 2.0064 - val_jaccard_coef: 6.0346e-18 - val_jaccard_coef_int: 6.0346e-18 - val_acc: 0.8755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85db855400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 52 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 128s - loss: 1.2886 - jaccard_coef: 9.0485e-18 - jaccard_coef_int: 9.0485e-18 - acc: 0.9201 - val_loss: 2.0064 - val_jaccard_coef: 6.0346e-18 - val_jaccard_coef_int: 6.0346e-18 - val_acc: 0.8755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85db8553c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "\n",
    "model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 52 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 128s - loss: 1.2886 - jaccard_coef: 9.0485e-18 - jaccard_coef_int: 9.0485e-18 - acc: 0.9201 - val_loss: 2.0064 - val_jaccard_coef: 6.0346e-18 - val_jaccard_coef_int: 6.0346e-18 - val_acc: 0.8755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85dbab6b38>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)\n",
    "\n",
    "model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm.. possibly some preprocessing doesn't work for the big images that work for M band needs for investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_val(aug=False):\n",
    "    print(\"let's pick some samples for validation\")\n",
    "    img = np.load(inDir + '/data/x_valALL_%d.npy' % N_Cls)\n",
    "    msk = np.load(inDir + '/data/y_valALL_%d.npy' % N_Cls)\n",
    "    x, y = get_patches(img, msk, amt=100, aug=aug)  # amt := attempt (maybe - i.e. attempting to create 3000 patches, without\n",
    "                                            # percentage area cover threshold.\n",
    "\n",
    "    print(\"Validation data shapes:\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    np.save(inDir + '/data/x_val_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_val_%d' % N_Cls, y)\n",
    "    \n",
    "    \n",
    "def stick_all_train():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 3300  # size of the P images (roughly)\n",
    "\n",
    "    # 25 training images grid\n",
    "    x = np.zeros((5 * s, 4 * s, 1))      # P\n",
    "    y = np.zeros((5 * s, 4 * s, N_Cls))  # axis=2 denote the class label\n",
    "\n",
    "    ids = sorted(DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "    \n",
    "    \n",
    "    # x start grid position (based on image size)\n",
    "    for i in range(5):\n",
    "        # y start grid position (based on image size)\n",
    "        for j in range(4):\n",
    "            id = ids[4 * i + j]\n",
    "\n",
    "            img = P(id)\n",
    "        \n",
    "            img = stretch_n(img)\n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            \n",
    "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n",
    "            \n",
    "            # generate training masks by class\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n",
    "    \n",
    "    print(\"x shape is:\")\n",
    "    print(x.shape)\n",
    "    print(\"y shape is:\")\n",
    "    print(y.shape)\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "    \n",
    "    np.save(inDir + '/data/x_trn_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_trn_%d' % N_Cls, y)\n",
    "    \n",
    "    \n",
    "def stick_all_val():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 3300  # size of the P images (roughly)\n",
    "\n",
    "    # 25 training images grid\n",
    "    x = np.zeros((5 * s, 1 * s, 1))      # P\n",
    "    y = np.zeros((5 * s, 1 * s, N_Cls))   # axis=2 denote the class label\n",
    "\n",
    "    ids = sorted(val_DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "\n",
    "    # x start grid position (based on image size)\n",
    "    for i in range(5):\n",
    "        # y start grid position (based on image size)\n",
    "        for j in range(1):\n",
    "            id = ids[1 * i + j]\n",
    "\n",
    "            img = P(id)\n",
    "            \n",
    "            img = stretch_n(img)\n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            \n",
    "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]  \n",
    "            \n",
    "            # generate training masks by class\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1, wkt_list_pandas=val_DF)[:s, :s]\n",
    "\n",
    "    print(\"x shape is:\")\n",
    "    print(x.shape)\n",
    "    print(\"y shape is:\")\n",
    "    print(y.shape)\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "\n",
    "    np.save(inDir + '/data/x_valALL_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_valALL_%d' % N_Cls, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stick_all_train()\n",
    "\n",
    "stick_all_val()\n",
    "make_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet_P():\n",
    "    inputs = Input((1, ISZ, ISZ))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(N_Cls, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', \n",
    "                  metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, y_val = np.load(inDir + '/data/x_val_%d.npy' % N_Cls), np.load(inDir + '/data/y_val_%d.npy' % N_Cls)\n",
    "img = np.load(inDir + '/data/x_trn_%d.npy' % N_Cls)\n",
    "msk = np.load(inDir + '/data/y_trn_%d.npy' % N_Cls)\n",
    "\n",
    "model = get_unet_P()\n",
    "\n",
    "# del x_trn\n",
    "# del y_trn\n",
    "x_trn, y_trn = get_patches(img, msk, amt=200, aug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGB+P band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_val(aug=False):\n",
    "    print(\"let's pick some samples for validation\")\n",
    "    img = np.load(inDir + '/data/x_valALL_%d.npy' % N_Cls)\n",
    "    msk = np.load(inDir + '/data/y_valALL_%d.npy' % N_Cls)\n",
    "    x, y = get_patches(img, msk, amt=100, aug=aug)  # amt := attempt (maybe - i.e. attempting to create 3000 patches, without\n",
    "                                            # percentage area cover threshold.\n",
    "\n",
    "    print(\"Validation data shapes:\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    np.save(inDir + '/data/x_val_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_val_%d' % N_Cls, y)\n",
    "    \n",
    "    \n",
    "def stick_all_train():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 3300  # size of the P images (roughly)\n",
    "\n",
    "    # 25 training images grid\n",
    "    x = np.zeros((5 * s, 4 * s, 3+1))      # RGB+P\n",
    "    y = np.zeros((5 * s, 4 * s, N_Cls))  # axis=2 denote the class label\n",
    "\n",
    "    ids = sorted(DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "    \n",
    "    \n",
    "    # x start grid position (based on image size)\n",
    "    for i in range(5):\n",
    "        # y start grid position (based on image size)\n",
    "        for j in range(4):\n",
    "            id = ids[4 * i + j]\n",
    "\n",
    "            img = RGB(id)\n",
    "            img_p = P(id)\n",
    "            \n",
    "            img = stretch_n(img)\n",
    "            img_p = stretch_n(img_p)\n",
    "            \n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            \n",
    "            x[s * i:s * i + s, s * j:s * j + s, :3] = img[:s, :s, :]  \n",
    "            x[s * i:s * i + s, s * j:s * j + s, 3] = img_p[:s, :s, :] \n",
    "            \n",
    "            # generate training masks by class\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n",
    "    \n",
    "    print(\"x shape is:\")\n",
    "    print(x.shape)\n",
    "    print(\"y shape is:\")\n",
    "    print(y.shape)\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "    \n",
    "    np.save(inDir + '/data/x_trn_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_trn_%d' % N_Cls, y)\n",
    "    \n",
    "    \n",
    "def stick_all_val():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 3300  # size of the P images (roughly)\n",
    "\n",
    "    # 25 training images grid\n",
    "    x = np.zeros((5 * s, 1 * s, 3+1))      # RGB+P\n",
    "    y = np.zeros((5 * s, 1 * s, N_Cls))   # axis=2 denote the class label\n",
    "\n",
    "    ids = sorted(val_DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "\n",
    "    # x start grid position (based on image size)\n",
    "    for i in range(5):\n",
    "        # y start grid position (based on image size)\n",
    "        for j in range(1):\n",
    "            id = ids[1 * i + j]\n",
    "\n",
    "            img = RGB(id)\n",
    "            img_p = P(id)\n",
    "            \n",
    "            img = stretch_n(img)\n",
    "            img_p = stretch_n(img_p)\n",
    "            \n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            \n",
    "            x[s * i:s * i + s, s * j:s * j + s, :3] = img[:s, :s, :]  \n",
    "            x[s * i:s * i + s, s * j:s * j + s, 3] = img_p[:s, :s, :]  \n",
    "            \n",
    "            # generate training masks by class\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1, wkt_list_pandas=val_DF)[:s, :s]\n",
    "\n",
    "    print(\"x shape is:\")\n",
    "    print(x.shape)\n",
    "    print(\"y shape is:\")\n",
    "    print(y.shape)\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "\n",
    "    np.save(inDir + '/data/x_valALL_%d' % N_Cls, x)\n",
    "    np.save(inDir + '/data/y_valALL_%d' % N_Cls, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stick_all_train()\n",
    "\n",
    "stick_all_val()\n",
    "make_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet_RGBP():\n",
    "    inputs = Input((3+1, ISZ, ISZ))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(N_Cls, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', \n",
    "                  metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, y_val = np.load(inDir + '/data/x_val_%d.npy' % N_Cls), np.load(inDir + '/data/y_val_%d.npy' % N_Cls)\n",
    "img = np.load(inDir + '/data/x_trn_%d.npy' % N_Cls)\n",
    "msk = np.load(inDir + '/data/y_trn_%d.npy' % N_Cls)\n",
    "\n",
    "model = get_unet_RGBP()\n",
    "\n",
    "# del x_trn\n",
    "# del y_trn\n",
    "x_trn, y_trn = get_patches(img, msk, amt=200, aug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "\n",
    "model.fit(x_trn, y_trn, batch_size=64, epochs=1, verbose=1, shuffle=True,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
